import scrapy
from scrapy_playwright.page import PageMethod
import re # Import re module

class DocsSpider(scrapy.Spider):
    name = 'docs_spider'
    allowed_domains = ['servicenow.com']
    start_urls = [
        'https://www.servicenow.com/docs/bundle/washingtondc-servicenow-platform/page/product/configuration-management/concept/identification-simulation.html?state=seamless'
    ]

    def start_requests(self):
        for url in self.start_urls:
            yield scrapy.Request(
                url,
                meta={
                    'playwright': True,
                    'playwright_include_page': True,
                    # Optional: define Playwright page methods to call
                    # 'playwright_page_methods': [
                    #     PageMethod('wait_for_selector', 'div.main-content'), # Example
                    # ],
                },
                callback=self.parse_page,
                errback=self.errback_close_page # Added errback
            )

    async def parse_page(self, response):
        page = response.meta.get('playwright_page')
        if not page:
            self.logger.error("Playwright page not found in response meta")
            return

        target_text_snippet = "Examine run logs Identification simulation provides run logs" # Shorter for selector
        target_text_full = "Examine run logs Identification simulation provides run logs which are generated by Identification and Reconciliation Engine (IRE). You can access these run logs for payload runs, to examine results and for debugging purposes. IRE payload output logs appear in a user friendly format on a central page."

        try:
            # Wait for a unique part of the target text to be visible
            await page.wait_for_selector(f'*:has-text("{target_text_snippet}")', timeout=30000)
            self.logger.info(f"Target text snippet '{target_text_snippet}' found on page.")

            # Extract all visible text from the page body
            extracted_text = await page.locator('body').inner_text()
            self.logger.info(f"Extracted text using page.locator('body').inner_text()")
            
            if not extracted_text or not extracted_text.strip():
                 self.logger.warning(f"Extracted text from body is empty or only whitespace. Trying page.evaluate('() => document.body.textContent').")
                 body_text_content = await page.evaluate("() => document.body.textContent")
                 if body_text_content:
                     extracted_text = body_text_content.strip()
                 else:
                     self.logger.error("Failed to extract any text content from the page.")
                     extracted_text = "" # Ensure extracted_text is a string
            
            # Normalize both extracted text and target text
            normalized_extracted_text = re.sub(r'\s+', ' ', extracted_text).strip()
            normalized_target_text = re.sub(r'\s+', ' ', target_text_full).strip()

            text_found = normalized_target_text in normalized_extracted_text
            self.logger.info(f"Normalized target text found in normalized extracted content: {text_found}")
            if not text_found:
                # Log snippets for debugging if not found
                self.logger.info(f"Normalized target snippet: {normalized_target_text[:200]}...")
                self.logger.info(f"Normalized extracted snippet (first 500 chars of target area if possible, else full): {normalized_extracted_text[:500]}...")


            yield {
                'url': response.url,
                'text_found': text_found,
                'content': extracted_text[:2000] + "..." if len(extracted_text) > 2000 else extracted_text, # Truncate for logs
            }

        except Exception as e:
            self.logger.error(f"Error during Playwright processing or text extraction: {e}")
            yield {
                'url': response.url,
                'text_found': False,
                'error': str(e),
                'content': None,
            }
        finally:
            if page and not page.is_closed():
                await page.close()
                self.logger.info(f"Playwright page closed for {response.url}")


    async def errback_close_page(self, failure):
        page = failure.request.meta.get('playwright_page')
        self.logger.error(f"Error in request: {failure.request.url}, {failure.getErrorMessage()}")
        if page and not page.is_closed():
            self.logger.info(f"Closing page due to error: {failure.getErrorMessage()} for url {failure.request.url}")
            await page.close()
